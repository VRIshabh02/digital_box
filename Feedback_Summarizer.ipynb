{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import heapq  \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "punctuation = punctuation + '\\n'\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_summarizer(input_text, number_of_sentence):\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    word_frequencies = {}  \n",
    "    for word in nltk.word_tokenize(input_text):  \n",
    "        if word not in stopWords:\n",
    "            if word not in punctuation:\n",
    "                if word not in word_frequencies.keys():\n",
    "                    word_frequencies[word] = 1\n",
    "                else:\n",
    "                    word_frequencies[word] += 1\n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "    for word in word_frequencies.keys():  \n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "\n",
    "    sentence_list = nltk.sent_tokenize(input_text)\n",
    "    sentence_scores = {}  \n",
    "    for sent in sentence_list:  \n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "\n",
    "    summary_sentences = heapq.nlargest(number_of_sentence, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "    summary = ' '.join(summary_sentences)  \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = pd.read_csv(r\"dataset/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_links(input_text):\n",
    "    pettern  = r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
    "    out_text = re.sub(pettern, ' ', input_text)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_repeated_characters(input_text):\n",
    "    pattern  = r'(.)\\1{2,}'\n",
    "    out_text = re.sub(pattern, r\"\\1\\1\", input_text)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(input_text):\n",
    "    replace = r'[/(){}\\[\\]|@âÂ,;\\?\\'\\\"\\*…؟–’،!&\\+-:؛-]'\n",
    "    out_text = re.sub(replace, \" \", input_text)\n",
    "    words = nltk.word_tokenize(out_text)\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    out_text = ' '.join(words)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stopwords(input_text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    tokens = tokenizer.tokenize(input_text)\n",
    "    out_text = [w for w in tokens if not w in stop_words]\n",
    "    out_text = ' '.join(out_text)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(input_text):\n",
    "    out_text = delete_links(input_text)\n",
    "    out_text = delete_repeated_characters(out_text)\n",
    "    out_text = clean_text(out_text)\n",
    "    out_text = delete_stopwords(out_text)\n",
    "    out_text = out_text.lower()\n",
    "    return out_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data['Processed Text'] = en_data['Text'].apply(text_prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_label_encoder = LabelEncoder()\n",
    "en_data['Category Encoded'] = en_label_encoder.fit_transform(en_data['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_X_train, en_X_test, en_y_train, en_y_test = train_test_split(en_data['Processed Text'], en_data['Category Encoded'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_test, ngram_range):\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, ngram_range))\n",
    "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_features_train, en_features_test = tfidf_features(en_X_train, en_X_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model_name):\n",
    "    if model_name == 'ridge_model':\n",
    "        model_name = RidgeClassifier()\n",
    "    elif model_name == 'random_forest_model':\n",
    "        model_name = RandomForestClassifier()\n",
    "    elif model_name == 'logistic_regression_model':\n",
    "        model_name = LogisticRegression()\n",
    "    elif model_name == 'kneighbors_model':\n",
    "        model_name = KNeighborsClassifier()\n",
    "    elif model_name == 'decision_tree_model':\n",
    "        model_name = DecisionTreeClassifier()\n",
    "    elif model_name == 'gaussian_nb_model':\n",
    "        model_name = GaussianNB()\n",
    "    model_name.fit(en_features_train.toarray(), en_y_train)\n",
    "    model_predictions = model_name.predict(en_features_test.toarray())\n",
    "    accuracy = accuracy_score(en_y_test, model_predictions)\n",
    "    print(f\"Accuracy on test for {model_name}: {accuracy}\")\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RidgeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m en_ridge_model \u001b[38;5;241m=\u001b[39m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mridge_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(en_ridge_model, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_ridge_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_model\u001b[39m(model_name):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mridge_model\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m         model_name \u001b[38;5;241m=\u001b[39m \u001b[43mRidgeClassifier\u001b[49m()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_forest_model\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      5\u001b[0m         model_name \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RidgeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "en_ridge_model = fit_model('ridge_model')\n",
    "pickle.dump(en_ridge_model, open('en_ridge_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_random_forest_model = fit_model('random_forest_model')\n",
    "pickle.dump(en_random_forest_model, open('en_random_forest_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_logistic_regression_model = fit_model('logistic_regression_model')\n",
    "pickle.dump(en_logistic_regression_model, open('en_logistic_regression_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_kneighbors_model = fit_model('kneighbors_model')\n",
    "pickle.dump(en_kneighbors_model, open('en_kneighbors_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_decision_tree_model = fit_model('decision_tree_model')\n",
    "pickle.dump(en_decision_tree_model, open('en_decision_tree_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_gaussian_nb_model = fit_model('gaussian_nb_model')\n",
    "pickle.dump(en_gaussian_nb_model, open('en_gaussian_nb_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = sid.polarity_scores(text)\n",
    "    if sentiment_scores['compound'] >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment_scores['compound'] <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data['Processed Text'] = en_data['Text'].apply(text_prepare)\n",
    "\n",
    "en_X_train, en_X_test = train_test_split(en_data['Processed Text'], test_size=0.2, random_state=0)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "en_features_train = vectorizer.fit_transform(en_X_train)\n",
    "en_features_test = vectorizer.transform(en_X_test)\n",
    "\n",
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(en_features_train, en_y_train)\n",
    "\n",
    "model_predictions = random_forest_model.predict(en_features_test)\n",
    "accuracy = accuracy_score(en_y_test, model_predictions)\n",
    "print(\"Accuracy on test set:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
